{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c49730",
   "metadata": {},
   "source": [
    "<img src=\"../../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Population Coding Exercises</h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import (KFold, LeaveOneOut, RepeatedKFold,\n",
    "                                     RepeatedStratifiedKFold, StratifiedKFold)\n",
    "from tqdm import tqdm\n",
    "\n",
    "import brain_observatory_utilities.datasets.behavior.data_formatting as behavior_utils\n",
    "from allensdk.brain_observatory.behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/\"\n",
    "    mp.set_start_method('fork')\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on CodeOcean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdf9e1-ff8a-41d0-9108-3f1e195cfd1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<h2>Exercise 2.1: Exploring Correlations between Neurons</h2>\n",
    "\n",
    "<p>\n",
    "Finally, we turn to examine the structure of the population activity.\n",
    "Does the structure of the population activity matter for this decoding, or is single-neuron tuning the whole name of the game? For example, if neurons 1 and 2 are co-active on trial 1 (both above their individual mean activity), does that carry any extra information? To explore this, we'll look at correlations between their responses.\n",
    "\n",
    "We'll look at this correlation in much more detail below, but we should first note some assumptions. Primarily, we are studying *spike counts*, or rates within time windows defined by the stimulus. This assumes that all spikes within the windows are equivalent, no matter their relative timing. It also assumes a specific set of time windows (set by the stimulus). In some cases, these assumptions may not be desirable (e.g., in studies of time-lagged spike-spike correlation, frequently used in studies of functional connectivity.)\n",
    "\n",
    "With that tangent aside, let's return to our observation that the neurons' activities (defined here by spike rates) are correlated.\n",
    "\n",
    "<p>\n",
    "<strong>Note:</strong>  For this exercise, there are not only comments with detailed prompts but often even code snippets for you to complete and/or run. In the later exercises we'll only provide the prompts that act as guiderails. \n",
    "</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73988021-7187-4fa4-84eb-f53dffd703e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Image decoding</h3>\n",
    "\n",
    "In the workshop we considered a change detection task and decoded whether there was a change. Here we want to decode which image was presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c9160-7321-4ffd-b85c-f74a27e78f49",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.1.a:</strong> As we did in the workshop, retrieve data of session 1065437523 from the  <code>VisualBehaviorNeuropixelsProjectCache</code>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714f6c7-5fcc-4af8-aa79-e970ba565597",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.1.b:</strong> Retrieve unit data, sort the units by depth, and filter for 'good' units using the same criteria as in the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037e149-28c5-4468-9421-5100370e7166",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "  \n",
    "<strong>Prompt 2.1.c:</strong> Consider good units in <code>area_of_interest='VISp'</code> and restrict the stimulus presentations to <code>stimulus_name='Natural_Images_Lum_Matched_set_ophys_G_2019'</code> and `active=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e9b8f-2a80-4082-b363-c64664459303",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "  \n",
    "<strong>Prompt 2.1.d:</strong> In the workshop we tried to decode the labels `'is_change'`. Here we want to decode the `'image_name'`. \n",
    "    <br>\n",
    "    Modify the <code>make_response_array</code> function accordingly. \n",
    "    <br>\n",
    "    Using a window size of 200ms, calculate the responses and labels using this <code>make_response_array</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c6f95-d774-40ee-8410-f678b5650554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_response_array(spike_times, stimulus_presentations, units, window=.2):\n",
    "\n",
    "    '''\n",
    "    Create an array of spike counts x stimulus presentations, and a corresponding list of stimulus labels.\n",
    "    spike_times: spike times \n",
    "    stimulus_presentation: stimulus presentation table\n",
    "    units: units table containing only the units to get the responses of\n",
    "    '''\n",
    "\n",
    "    # Sort spike times chronologically; necessary for the binary search later\n",
    "    sorted_spikes = dict()\n",
    "    for iu in units.index:\n",
    "        # Use mergesort/timsort since most spike_times are already sorted\n",
    "        sorted_spikes[iu] = np.sort(spike_times[iu], kind='mergesort')\n",
    "\n",
    "    # Create our own copy of stimulus presentations and sort by presentation start time chronologically\n",
    "    # Sorting of stimulus_presentations isn't necessary, but it speeds up the vectorized `searchsorted(...)`\n",
    "    stimulus_presentations = stimulus_presentations.sort_values(by='start_time', kind='mergesort', inplace=False)\n",
    "\n",
    "    # Calculate the duration of stimulus presentations, and drop NaN durations\n",
    "    stimulus_presentations['duration'] = stimulus_presentations['end_time'] - stimulus_presentations['start_time']\n",
    "    stimulus_presentations.dropna(subset='duration', inplace=True)\n",
    "    \n",
    "    # Warn if window size is too big\n",
    "    if np.any(window > stimulus_presentations['duration']):\n",
    "        print('Warning: window size longer than stimulus presentation')\n",
    "\n",
    "    responses_by_unit = list()\n",
    "    for iu in units.index:\n",
    "        unit_spike_times = sorted_spikes[iu]\n",
    "\n",
    "        # Determine the first and last spike time for each stimulus presentation\n",
    "        start_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time'])\n",
    "        end_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time'] + window)\n",
    "\n",
    "        # Calculate the response rate for each stimulus presentation\n",
    "        responses_by_unit.append((end_is - start_is) / window)\n",
    "\n",
    "    # responses_by_unit has each row as a unit, and each column as a stimulus, flip so that rows are stimuli\n",
    "    responses = np.transpose(responses_by_unit)\n",
    "\n",
    "    # Extract the labels that match the responses from our sorted stimulus presentations table\n",
    "    labels = \n",
    "    \n",
    "    return responses, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9070dbc-a6b3-452a-b20d-41f2759f942f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses, labels = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3772d83f-0e78-4897-9262-373505c203cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.1.e:</strong> Now let's decode the presented images from these responses using 5-fold cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cd5c6-36f9-47ef-96ab-3377cec47ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "confusions = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in KFold(n_splits=5, shuffle=True).split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)    \n",
    "    print(accuracy)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize='pred'))\n",
    "    \n",
    "print(f\"\\nmean accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"chance: {1/conditions.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275a2a1-2529-4782-80f6-3c2399c69186",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Computing correlation matrices</h3>\n",
    "\n",
    "For the following analysis, we will look at Pearson correlations: the Pearson correlation for a pair of neurons is the covariance divided by the product of the neurons' standard deviations. This normalizes the measure so that its maximum is 1 and minimum is -1, which makes it easier to interpret than covariances.\n",
    "\n",
    "So far, we have not considered how much of the covariance or correlation is stimulus-driven (e.g., reflecting neurons with similar tuning responding to the same stimulus at the same time) vs arising from other sources. \n",
    "\n",
    "The correlations due to the stimulus properties are called *signal correlations*, whereas correlations due to other sources (including random variability within the eyes and the brain) are called *noise correlations*. The correlations we considered above encapsulate both of these factors, and are called *total* correlations.\n",
    "\n",
    "To separate these out, we'll now compute and compare all 3 (Pearson) correlation matrices: the total correlations, signal correlations, and noise correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef120c2f-3d79-4e1d-b1db-c3ad5ee5c33c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.1.f:</strong> First, calculate and plot the total correlations (using `np.corrcoef`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5354d1e-a329-4b9b-8563-5ff5f1de0c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_correlations = np.corrcoef(responses.T)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(total_correlations, cmap='bwr', clim=(-1,1))\n",
    "plt.colorbar(im, ax=ax, label='Correlation coefficient')\n",
    "ax.set_title('Total Correlations')\n",
    "ax.set_xlabel('Unit #')\n",
    "ax.set_ylabel('Unit #')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c6d72-3b80-4a44-858f-7f4981962ee0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, we'll compute the signal correlations. These are the correlations in the neurons' average response to each stimulus, computed across stimuli. As the name implies, they tell us how much two neurons' mean (trial averaged) activities co-vary as the stimulus changes.\n",
    "\n",
    "To compute these, we'll first calculate the average activities for each stimulus identity and neuron.\n",
    "    \n",
    "<strong>Prompt 2.1.g:</strong> Plot the tuning curves for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2de8c-60b6-45fb-ac1c-ef05bd3935be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Compute trial-averaged response to each stimulus (aka tuning curves) using our response array\n",
    "stimuli = stimulus_presentations['image_name'].unique()\n",
    "num_stim = len(stimuli)\n",
    "\n",
    "tuning_curves = np.zeros((num_units, num_stim))\n",
    "\n",
    "for j, stim in enumerate(stimuli):\n",
    "    stim_idx = np.where(labels == stim)\n",
    "    tuning_curves[:, j] = np.mean(responses[stim_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27488ad2-db9c-4f8e-848f-51847f195ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1d6d0-5adc-46fa-9ae4-34b4b17a6636",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.1.h:</strong> The signal correlation matrix is the pearson correlation of neuron's trial-averaged responses---the similarity of their tuning curves. Calculate and plot the signal correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1214165c-d328-4c3a-8826-74a0bfb24472",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Finally, let's compute the noise correlations. These are the correlations in the responses to each stimulus, reflecting the (correlated) trial-to-trial variability in the neural population. These correlations can come from synaptic connections (or indirect connections) between the neurons, so that when neuron A fires more on a given trial, neuron B also fires more (excitatory connection), or neuron B fires less (inhibitory connection). The noise correlations can also come from shared input. For example, if neuron C has an excitatory projection to both neurons A and B, then on trials where neuron C has increased firing rate, then both neurons A and B will also show increased firing.\n",
    "\n",
    "These noise correlations are defined on a per-stimulus basis and can vary somewhat between stimuli. For sake of interest, we'll plot below the correlation matrices for two different stimuli, and we'll later make use of the average correlation matrix (averaged over all 8 orientations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd59d22-221f-4c98-9057-12bbef10e8b1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "<strong>Prompt 2.1.i:</strong> Calculate the noise correlations for each stimulus as well as their average across stimuli\n",
    "    \n",
    "Since noise correlations are single-trial correlations, if a neuron does not respond to a particular stimulus condition it can generate NaNs when we divide by the standard deviation of the responses. To ignore these, we use numpy's masked array module, numpy.ma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c95b21-5e90-45c1-a8c3-d19393edc6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_correlations = np.zeros((len(conditions), num_units, num_units)) # initialize the noise correlation matrix for each stimulus condition\n",
    "\n",
    "for i, condition in enumerate(stimuli):\n",
    "    condition_idx = np.where(labels == condition)\n",
    "    responses_condition = responses[condition_idx]    \n",
    "    noise_correlations[i] = np.ma.corrcoef(responses_condition.T)\n",
    "    \n",
    "mean_noise_correlations = np.mean(noise_correlations,axis=0)\n",
    "\n",
    "print('Mean noise correlation: {}'.format(np.mean(np.triu(mean_noise_correlations, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae6902-13b5-4403-91b2-03eecdcf2d08",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Prompt 2.1.j:</strong> Plot the noise correlations for two different stimuli, as well as their average across stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0b6d7-6ef3-4296-b93e-fd6d8f963621",
   "metadata": {},
   "source": [
    "Note that noise correlations can vary between stimuli! What differences do you see between these two noise correlation matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e9f79-7d21-46f1-9009-1217e4b61c7e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "A common interpretation of noise correlations is that they can arise from synapses between, or common input to, a pair of neurons. These can also affect (or, through Hebbian learning, reflect) stimulus tuning. So we might expect noise and signal correlations to be correlated.\n",
    "    \n",
    "The scipy.stats function pearsonr computes the pearson correlation and a a p-value from the hypothesis test where the null ypothesis is zero correlation. \n",
    "    \n",
    "<strong>Prompt 2.1.k:</strong> Are the noise and signal correlations significantly correlated?   \n",
    "Make sure to only compare the off-diagonal elements of the noise and signal correlation matrices, since the diagonal elements are all 1 by definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839ee89-0417-41af-9d4a-88602383d121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1185ea7-8e7f-49cd-9963-38e82a1acae3",
   "metadata": {},
   "source": [
    "Various computational models make predictions about the relation between noise and signal correlations. For example, the local competition algorithm for sparse coding, which was once a leading theory of V1 computation, predicts a negative relationship between noise and signal correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eab939-6839-40ea-b610-d67fb51837e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Population decoding with and without noise correlations</h3>\n",
    "\n",
    "While the noise correlations are weak, it is worth asking whether or not -- from an information processing standpoint -- we can treat each neuron as independent. In other words, are the noise correlations weak enough that they can be ignored?\n",
    "\n",
    "To test this, we'll return to our decoding analysis, and we will try decoding from synthetic data in which we artificially remove the noise correlations. We do this by trial-shuffling the neural data. This creates a fake dataset in which non-simultaneously-recorded neural activities are assembled to make the population response vectors, and it removes the noise correlations.\n",
    "\n",
    "<strong>Prompt 2.1.l:</strong> To do this, we go through the data, and for each stimulus, and for each neuron, we randomly (and independently) re-order the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844c04d-c484-423b-ba52-3ad4140383ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trial_shuffle_responses(responses, conditions):\n",
    "    \n",
    "    shuffled_responses = responses.copy()\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "        condition_idx = np.where(labels == condition)\n",
    "\n",
    "        for j in range(num_units):\n",
    "            responses_unit_condition = responses[condition_idx, j].reshape(-1).copy()\n",
    "            np.random.shuffle(responses_unit_condition) # shuffle in place\n",
    "            shuffled_responses[condition_idx, j] = responses_unit_condition\n",
    "            \n",
    "    return shuffled_responses\n",
    "\n",
    "shuffled_responses = trial_shuffle_responses(responses, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45354be1-41b9-4b69-bd7a-bbdf0abb0961",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Prompt 2.1.m:</strong>  First, let's double-check that our shuffling worked correctly. Compute the noise correlations in the shuffled data, and plot the histogram of the off-diagonal elements of the true noise correlations and of the shuffled-response noise correlations. \n",
    "    \n",
    "We'd expect to see that the trial-shuffled noise correlations are distributed closely around 0, with non-zero values only due to the finite sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7952191-3d0a-45d4-9c8d-542706802944",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<strong>Prompt 2.1.n:</strong>     \n",
    "Now let's decode from the trial-shuffled responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a0574-2949-408b-a19b-0d467b171e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ca67b-127b-4899-97db-1a204c78fc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5183bfd6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<h2>Exercise 2.2: Decoding for Different Brain Areas, Behavioral States, and Stimuli</h2>\n",
    "\n",
    "<p>\n",
    "In Exercise 2.1 we looked at decoding performance, restriciting the analysis to \n",
    "<ol>\n",
    "<li>one brain area ('VISp'),</li>\n",
    "<li>one stimulus set ('Natural_Images_Lum_Matched_set_ophys_G_2019'), and</li>\n",
    "<li>only one type of trials ('active')</li>\n",
    "</ol>\n",
    "It's time to generalize! Let's plot the decoding performance for each brain area recorded seperated by running/not running trials. Consider further all stimulus sets with moderate amount (10-500) of stimulus conditions.\n",
    "\n",
    "<p>\n",
    "<strong>Note:</strong>  For this exercise, there are comments with detailed prompts that act as guiderails. But feel free to try completing the task objectives using your own approach first, and consulting our prompts if you get stuck.\n",
    "</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e6aa9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.a:</strong> As we did in the workshop, retrieve data of session 1065437523 from the  <code>VisualBehaviorNeuropixelsProjectCache</code>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb57ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.b:</strong> Obtain the <strong>annotated</strong> stimulus presentations for the session using the <code>behavior_utils</code> package.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd1c31",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.c:</strong> Plot histograms of <code>mean_pupil_width</code> and <code>mean_running_speed</code>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afa45f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.d:</strong> As we just observed, in the VB dataset, the mice were nearly always running. To consider a dataset that includes trials where mice are 'not running', let's turn to the VC dataset. Retrieve data of session 798911424 from the <code>EcephysProjectCache</code>.\n",
    "\n",
    "</div>\n",
    "<details>\n",
    "    <summary>Click for <strong>Hint:</strong></summary>\n",
    "    The manifest is located in the data subfolder <code>allen-brain-observatory/visual-coding-neuropixels/ecephys-cache/manifest.json</code>.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e928f3fc",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> The Visual Coding (VC) stimulus sets </h2> \n",
    "<img src=\"../../resources/neuropixels_stimulus_sets.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769088e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.e:</strong> Retrieve unit data, sort the units by depth, and filter for 'good' units using the same criteria as in the workshop.\n",
    "\n",
    "</div>\n",
    "<details>\n",
    "    <summary>Click for <strong>Hints:</strong></summary>\n",
    "    Unlike for VB (Prompt 2.2.b), here the session object has no <code>get_units</code> method, but a <code>units</code> attribute that already contains channel information, thus no merging is necessary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6073bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.f:</strong> Get the <code>stimulus_presentations</code> table for the session and create a list of the <code>stimulus_names</code> with at least 10 but less than 500 stimulus conditions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01425bc5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.g:</strong> Calculate the average running speed for each trial and add them as new column <code>'mean_running_speed'</code> to the stimulus table.\n",
    "\n",
    "</div>\n",
    "<details>\n",
    "    <summary>Click for a <strong>Hint:</strong></summary>\n",
    "    For VB the <code>behavior_utils</code> package provides a convenient function to obtain an annotated stimulus table, whereas here for VC we need to do spell out the calculation steps ourselves.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3b6c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.h:</strong> Plot a histogram of running speeds, indicating a threshold of 5 cm/s.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246615c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.i:</strong> Add a new column to the stimulus table named <code>'running'</code>, with values set to <code>True</code> if the running speed is greater than 5 cm/s, otherwise <code>False</code>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a202af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.j:</strong> Try using the <code>make_response_array</code> function using the session's spike times and stimulus table.\n",
    "<p>\n",
    "Why does it fail? Modify the stimulus table as needed to ensure the function succeeds. (Alternatively, you could modify the function.)\n",
    "    \n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>Click for a <strong>Hint:</strong></summary>\n",
    "    We want to decode <code>'stimulus_condition_id'</code>. Rename (or duplicate) appropriate columns to <code>'end_time'</code> and <code>'image_name'</code> respectively.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6a6ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.k:</strong> Plot the number of good units (y-axis) for each brain structure (x-axis).  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8b2aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.l:</strong> Create a function <code>decode(area_of_interest, selection, window, n_splits)</code> that returns the accuracies of stimulus decoding in <code>area_of_interest</code> for a given <code>selection</code> of stimulus presentations.\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>Click for <strong>Hints:</strong></summary>\n",
    "    Revisiting the steps performed in the workshop will help to create the function that\n",
    "    <ol>\n",
    "    <li>selects from the <code>good_units</code> the ones in the <code>area_of_interest</code> (see Prompt 2.2.e)</li>\n",
    "    <li>selects the stimulus presentations from our annotated stimulus presentations table according to the <code>selection</code> dictionary (see Prompt 2.2.f+g)</li>\n",
    "    <li>creates <code>responses</code> and <code>labels</code> using the function <code>make_response_array</code> with window size <code>window</code></li>\n",
    "    <li>uses <code>sklearn.model_selection.KFold</code> to split the data into \"train\" and \"test\" sets for <code>n_splits</code> iterations, and for each iteration trains a <code>sklearn.svm.SVC</code> on the training set and calculates the accuracy on the test set</li>\n",
    "    <li>returns a list/array of length <code>n_splits</code> with the accuracies for each split</li>\n",
    "    </ol>\n",
    "    The signature of the function with default args could be \n",
    "    <p>\n",
    "    <code>def decode(area_of_interest='VISp',\n",
    "            selection={\"stimulus_name\": 'natural_scenes', \"running\": True},\n",
    "            window=.25,\n",
    "            num_splits=5):</code>\n",
    "    </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939c746",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.m:</strong> Equipped with this function, \n",
    "<p> for each <code>stimulus_name</code> from Prompt 2.2.f, (i.e. 'gabors', 'drifting_gratings', 'static_gratings', 'natural_scenes', 'drifting_gratings_contrast'),\n",
    "<p> &emsp;&emsp; for both <code>\"running\"</code> and <code>\"not_running\"</code> trials,\n",
    "<p> &emsp;&emsp;&emsp;&emsp; calculate and store the decoding accuracy for each recorded brain <code>structure</code>.\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>Click to receive a <strong>Hint</strong> for faster processing:</summary>\n",
    "    You could use <code>multiprocessing.Pool(processes).map()</code> to speed up processing by applying the <code>decode</code> function to all <code>structures</code> in parallel.\n",
    "    <br>You might run out of memory if you use too many <code>processes</code>. On CodeOcean, don't use more than <code>os.environ.get(\"CO_CPUS\")</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c98141",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.2.n:</strong> For each considered <code>stimulus_name</code>, create a figure with an error bar plot of decoding accuracy (y-axis) for each brain area (x-axis) for \"running\" trials. Add another error bar plot for \"not_running\" trials using a different color in the same figure, and include a horizontal line indicating chance level performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa5430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a430aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93dd1efb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<h2>Exercise 2.3: Noise Correlations and Modulation by Running</h2>\n",
    "\n",
    "<p>\n",
    "In this exercise, we will explore how running modulates neural responses and affects noise correlations. Specifically, we will:\n",
    "<ol>\n",
    "<li>Plot total, signal, and noise correlations</li>\n",
    "<li>Plot the correlations between neural responses and running speed</li>\n",
    "<li>Compare the noise correlations of all units versus highly modulated units</li>\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "<strong>Note:</strong> For this exercise, there are comments with detailed prompts that act as guidelines. However, feel free to try completing the task objectives using your own approach first, and consult our prompts if you get stuck.\n",
    "</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6d488",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.a:</strong> Make sure you have completed the steps in Prompts 2.2.d-j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66521f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "  \n",
    "<strong>Prompt 2.3.b:</strong> Consider good units in <code>area_of_interest='VISp'</code> and restrict the stimulus presentations to <code>selection={\"stimulus_name\": 'drifting_gratings', \"running\": True}</code>. Using a window size of 250ms, calculate the responses and labels using the <code>make_response_array</code> function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0fb16",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.c:</strong> Calculate and plot total, signal, and mean noise correlations.\n",
    "\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>Click for a <strong>Hint</strong></summary>\n",
    "    See Exercise 2.1\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b383e7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "<strong>Prompt 2.3.d:</strong> For each stimulus condition, calculate the correlation with <code>'mean_running_speed'</code> for each unit. Plot the array (size #conditions x #units) of running speed correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f7078",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.e:</strong> Consider the stimulus condition with the most stimulus presentations. For this condition, plot the <code>'speed_correlations'</code>, showing a threshold of 0.75. Get the indices of the <code>'highly_modulated_units'</code> whose correlation with running speed is greater than 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72cbed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "<strong>Prompt 2.3.f:</strong> Create plots comparing the noise correlations of <code>'highly_modulated_units'</code> to all units.\n",
    "    \n",
    "<ol>\n",
    "<li>Plot the responses (for the considered condition) of those <code>'highly_modulated_units'</code> together with the running speed (use a separate y-axis for the latter).</li>\n",
    "<li>In another panel, plot the noise correlations (for the considered condition) of the <code>'highly_modulated_units'</code>.</li>\n",
    "<li>In another panel, plot the histogram of the off-diagonal elements of the noise correlations (for the considered condition) of (1) all units and (2) <code>'highly_modulated_units'</code> (use density, not counts).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824f83d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.g:</strong> Create synthetic data with removed noise correlations by trial-shuffling the neural data (for each condition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935f5b6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.h:</strong> Decode the stimuli using a linear SVM on the true and shuffled responses. Repeatedly split into 'train' and 'test' data using <code>StratifiedKFold</code> or <code>LeaveOneOut</code> and calculate the accuracies averaged over splits.\n",
    "<p> Why not just use KFold as we did in the workshop?\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>Click for a <strong>Hint:</strong></summary>\n",
    "    Consider the number of presentations of each stimulus condition.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7341749",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<strong>Prompt 2.3.i:</strong> We considered <code>'drifting_gratings'</code>. Change to a static stimulus set and run all cells of this exercise again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dde1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
